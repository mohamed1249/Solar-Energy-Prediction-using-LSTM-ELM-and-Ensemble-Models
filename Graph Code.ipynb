{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-07-19 18:00:00', '2023-07-19 19:00:00',\n",
       "               '2023-07-19 20:00:00', '2023-07-19 21:00:00',\n",
       "               '2023-07-19 22:00:00', '2023-07-19 23:00:00',\n",
       "               '2023-07-20 00:00:00', '2023-07-20 01:00:00',\n",
       "               '2023-07-20 02:00:00', '2023-07-20 03:00:00',\n",
       "               ...\n",
       "               '2023-08-18 08:00:00', '2023-08-18 09:00:00',\n",
       "               '2023-08-18 10:00:00', '2023-08-18 11:00:00',\n",
       "               '2023-08-18 12:00:00', '2023-08-18 13:00:00',\n",
       "               '2023-08-18 14:00:00', '2023-08-18 15:00:00',\n",
       "               '2023-08-18 16:00:00', '2023-08-18 17:00:00'],\n",
       "              dtype='datetime64[ns]', length=720, freq=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genrate_12_hours():\n",
    "    time_zone = []\n",
    "    \n",
    "    def hourly_it(start, finish):\n",
    "        while finish > start:\n",
    "                start = start + timedelta(hours=1)\n",
    "                yield start\n",
    "\n",
    "    start = datetime.now().replace(minute=0, second=0, microsecond=0)\n",
    "    finish = start + timedelta(days=30)\n",
    "    for hour in hourly_it(start, finish):\n",
    "        time_zone.append(hour)\n",
    "    return pd.to_datetime(time_zone)\n",
    "\n",
    "time = genrate_12_hours()\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2023-03-01T00:00:00.000000000')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish = time[-1]\n",
    "\n",
    "data = pd.read_csv('plotting data/Full Data.csv')\n",
    "len_data_we_have = len(data)\n",
    "data['Date Time'] = pd.to_datetime(data['Date Time'])\n",
    "start = data['Date Time'].iloc[-1].to_datetime64()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-08-18 17:00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-03-01 01:00:00', '2023-03-01 02:00:00',\n",
       "               '2023-03-01 03:00:00', '2023-03-01 04:00:00',\n",
       "               '2023-03-01 05:00:00', '2023-03-01 06:00:00',\n",
       "               '2023-03-01 07:00:00', '2023-03-01 08:00:00',\n",
       "               '2023-03-01 09:00:00', '2023-03-01 10:00:00',\n",
       "               ...\n",
       "               '2023-08-18 08:00:00', '2023-08-18 09:00:00',\n",
       "               '2023-08-18 10:00:00', '2023-08-18 11:00:00',\n",
       "               '2023-08-18 12:00:00', '2023-08-18 13:00:00',\n",
       "               '2023-08-18 14:00:00', '2023-08-18 15:00:00',\n",
       "               '2023-08-18 16:00:00', '2023-08-18 17:00:00'],\n",
       "              dtype='datetime64[ns]', length=4097, freq=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hours = []\n",
    "while start < finish:\n",
    "    start +=  np.timedelta64(1,'h')\n",
    "    new_hours.append(start)\n",
    "pd.to_datetime(new_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2023-03-01 01:00:00\n",
       "1      2023-03-01 02:00:00\n",
       "2      2023-03-01 03:00:00\n",
       "3      2023-03-01 04:00:00\n",
       "4      2023-03-01 05:00:00\n",
       "               ...        \n",
       "4092   2023-08-18 13:00:00\n",
       "4093   2023-08-18 14:00:00\n",
       "4094   2023-08-18 15:00:00\n",
       "4095   2023-08-18 16:00:00\n",
       "4096   2023-08-18 17:00:00\n",
       "Name: 0, Length: 4097, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(new_hours).to_frame().reset_index().iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7638 entries, 0 to 7637\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Unnamed: 0  7638 non-null   int64         \n",
      " 1   Date Time   7638 non-null   datetime64[ns]\n",
      " 2   Solar Avg   7638 non-null   float64       \n",
      " 3   lag_1       7638 non-null   float64       \n",
      " 4   lag_2       7638 non-null   float64       \n",
      " 5   lag_3       7638 non-null   float64       \n",
      " 6   lag_4       7638 non-null   float64       \n",
      " 7   lag_5       7638 non-null   float64       \n",
      " 8   lag_6       7638 non-null   float64       \n",
      " 9   lag_7       7638 non-null   float64       \n",
      " 10  lag_8       7638 non-null   float64       \n",
      " 11  lag_9       7638 non-null   float64       \n",
      " 12  lag_10      7638 non-null   float64       \n",
      " 13  lag_11      7638 non-null   float64       \n",
      " 14  lag_12      7638 non-null   float64       \n",
      " 15  lag_13      7638 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int64(1)\n",
      "memory usage: 954.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-03 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-03 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-03 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11730</th>\n",
       "      <td>2023-08-18 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11731</th>\n",
       "      <td>2023-08-18 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>2023-08-18 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11733</th>\n",
       "      <td>2023-08-18 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11734</th>\n",
       "      <td>2023-08-18 17:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11735 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date Time\n",
       "0     2022-01-03 13:00:00\n",
       "1     2022-01-03 14:00:00\n",
       "2     2022-01-03 15:00:00\n",
       "3     2022-01-03 16:00:00\n",
       "4     2022-01-03 17:00:00\n",
       "...                   ...\n",
       "11730 2023-08-18 13:00:00\n",
       "11731 2023-08-18 14:00:00\n",
       "11732 2023-08-18 15:00:00\n",
       "11733 2023-08-18 16:00:00\n",
       "11734 2023-08-18 17:00:00\n",
       "\n",
       "[11735 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dates = pd.concat([data['Date Time'],pd.to_datetime(new_hours).to_frame().reset_index().iloc[:,1]]).reset_index().iloc[:,1]\n",
    "new_data = new_dates.to_frame().rename(columns={0:'Date Time'})\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11735 entries, 0 to 11734\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date Time  11735 non-null  datetime64[ns]\n",
      " 1   Solar Avg  0 non-null      float64       \n",
      " 2   lag_1      0 non-null      float64       \n",
      " 3   lag_2      0 non-null      float64       \n",
      " 4   lag_3      0 non-null      float64       \n",
      " 5   lag_4      0 non-null      float64       \n",
      " 6   lag_5      0 non-null      float64       \n",
      " 7   lag_6      0 non-null      float64       \n",
      " 8   lag_7      0 non-null      float64       \n",
      " 9   lag_8      0 non-null      float64       \n",
      " 10  lag_9      0 non-null      float64       \n",
      " 11  lag_10     0 non-null      float64       \n",
      " 12  lag_11     0 non-null      float64       \n",
      " 13  lag_12     0 non-null      float64       \n",
      " 14  lag_13     0 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(14)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "for col in data.iloc[:,2:].columns:\n",
    "    new_data[col] = np.nan\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11735 entries, 0 to 11734\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date Time  11735 non-null  datetime64[ns]\n",
      " 1   Solar Avg  7638 non-null   float64       \n",
      " 2   lag_1      7638 non-null   float64       \n",
      " 3   lag_2      7638 non-null   float64       \n",
      " 4   lag_3      7638 non-null   float64       \n",
      " 5   lag_4      7638 non-null   float64       \n",
      " 6   lag_5      7638 non-null   float64       \n",
      " 7   lag_6      7638 non-null   float64       \n",
      " 8   lag_7      7638 non-null   float64       \n",
      " 9   lag_8      7638 non-null   float64       \n",
      " 10  lag_9      7638 non-null   float64       \n",
      " 11  lag_10     7638 non-null   float64       \n",
      " 12  lag_11     7638 non-null   float64       \n",
      " 13  lag_12     7638 non-null   float64       \n",
      " 14  lag_13     7638 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(14)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "new_data.iloc[:len(data),1:] = data.iloc[:,2:]\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "Ens = keras.models.load_model('models/Ens.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7638"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11735"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAPTOP WORLD\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Ens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\python\\projects\\Upwork-Projects\\JS ELM\\Graph Code.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/python/projects/Upwork-Projects/JS%20ELM/Graph%20Code.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     data_copy\u001b[39m.\u001b[39mloc[last_index,\u001b[39m'\u001b[39m\u001b[39mlag_2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_copy\u001b[39m.\u001b[39mloc[last_index\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlag_1\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/python/projects/Upwork-Projects/JS%20ELM/Graph%20Code.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     data_copy\u001b[39m.\u001b[39mloc[last_index,\u001b[39m'\u001b[39m\u001b[39mlag_1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_copy\u001b[39m.\u001b[39mloc[last_index\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSolar Avg\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/python/projects/Upwork-Projects/JS%20ELM/Graph%20Code.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     data_copy\u001b[39m.\u001b[39mloc[last_index,\u001b[39m'\u001b[39m\u001b[39mSolar Avg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m target_scaler\u001b[39m.\u001b[39minverse_transform(Ens\u001b[39m.\u001b[39mpredict(data_scaler\u001b[39m.\u001b[39mtransform(data_copy\u001b[39m.\u001b[39miloc[last_index\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m:]\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) )))[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/python/projects/Upwork-Projects/JS%20ELM/Graph%20Code.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     last_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/python/projects/Upwork-Projects/JS%20ELM/Graph%20Code.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m data_copy\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mplotting data/Ens_preds_to_plot.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Ens' is not defined"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "# load the scaler\n",
    "target_scaler = load(open('scalers/target_scaler.pkl', 'rb'))\n",
    "data_scaler = load(open('scalers/data_scaler.pkl', 'rb'))\n",
    "\n",
    "\n",
    "data_copy = new_data.copy()\n",
    "last_index = len(data)\n",
    "for h in range(len(pd.to_datetime(new_hours).to_frame().reset_index().iloc[:,1])):\n",
    "    data_copy.loc[last_index,'lag_13'] = data_copy.loc[last_index-1,'lag_12']\n",
    "    data_copy.loc[last_index,'lag_12'] = data_copy.loc[last_index-1,'lag_11']\n",
    "    data_copy.loc[last_index,'lag_11'] = data_copy.loc[last_index-1,'lag_10']\n",
    "    data_copy.loc[last_index,'lag_10'] = data_copy.loc[last_index-1,'lag_9']\n",
    "    data_copy.loc[last_index,'lag_9'] = data_copy.loc[last_index-1,'lag_8']\n",
    "    data_copy.loc[last_index,'lag_8'] = data_copy.loc[last_index-1,'lag_7']\n",
    "    data_copy.loc[last_index,'lag_7'] = data_copy.loc[last_index-1,'lag_6']\n",
    "    data_copy.loc[last_index,'lag_6'] = data_copy.loc[last_index-1,'lag_5']\n",
    "    data_copy.loc[last_index,'lag_5'] = data_copy.loc[last_index-1,'lag_4']\n",
    "    data_copy.loc[last_index,'lag_4'] = data_copy.loc[last_index-1,'lag_3']\n",
    "    data_copy.loc[last_index,'lag_3'] = data_copy.loc[last_index-1,'lag_2']\n",
    "    data_copy.loc[last_index,'lag_2'] = data_copy.loc[last_index-1,'lag_1']\n",
    "    data_copy.loc[last_index,'lag_1'] = data_copy.loc[last_index-1,'Solar Avg']\n",
    "    data_copy.loc[last_index,'Solar Avg'] = target_scaler.inverse_transform(Ens.predict(data_scaler.transform(data_copy.iloc[last_index-1,2:].to_numpy().reshape(1, -1) )))[0][0]\n",
    "    last_index += 1\n",
    "data_copy.to_csv(f'plotting data/Ens_preds_to_plot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ens_preds = pd.read_csv('plotting data/Ens_preds_to_plot.csv').iloc[len_data_we_have:,:].set_index('Date Time')\n",
    "Ens_data = pd.read_csv('plotting data/Ens_preds_to_plot.csv').iloc[-(6*30*24):len_data_we_have+1,:].set_index('Date Time')\n",
    "Ens_data = Ens_data.loc[Ens_data.index >= '2022-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create three line plots with two lines each\n",
    "trace5 = go.Scatter(x=Ens_data.index, y=Ens_data['Solar Avg'], name='Real Value', showlegend=True)\n",
    "trace6 = go.Scatter(x=Ens_preds.index, y=Ens_preds['Solar Avg'], name='Ens Predictions', showlegend=True)\n",
    "\n",
    "# Create a subplot with three rows and two columns\n",
    "fig = make_subplots(rows=1, cols=1, y_title='Solar Price', x_title='Date')\n",
    "\n",
    "# Add the six line plots to the subplot\n",
    "fig.add_trace(trace5, row=1, col=1)\n",
    "fig.add_trace(trace6, row=1, col=1)\n",
    "\n",
    "# Update the subplot layout and legend\n",
    "fig.update_layout(height=900, width=2000, title_text=\"Solar Predictions\")\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01\n",
    "))\n",
    "\n",
    "# Save the subplot to a file\n",
    "fig.write_html(\"subplot.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
